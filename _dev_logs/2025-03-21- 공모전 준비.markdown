---
layout: post
title: "제4회 고용노동 공공데이터 활용 공모전 탐색"
date: 2025-03-21
typora-root-url: ../
image_style: "max-width:80%; display:block; margin:1em auto; border-radius:10px; box-shadow:2px 2px 8px rgba(0,0,0,0.8);"
---

[제4회 고용노동 공공데이터 활용 공모전](https://www.2025datacontest.co.kr)



[**고용노동부_한권으로 통하는 고용노동정책**](https://www.moel.go.kr/info/publicdata/majorpublish/majorPublishView.do?bbs_seq=20250200573)

상당히 많은 정책이 시민들을 위해 유지되고 있음.

그러나 총 319페이지로 상당한 양이기 때문에 해당 사용유저가 원하는 정보를 찾으려면 웹 Viewer로 보던, PDF로 보던 Ctrl + F (검색기능)이 작동을 하지 않기 때문에 하나하나 관련 분야가 있는 페이지들을 하나하나 살펴보며 찾아 볼 수 밖에 없음.

<br>

---



# 만들 기능들

1. 유저의 데이터(나이, 성별, 지금 찾는 분야, 취업에 도움을 받고 싶은지, 최근 출산지원금이 있는지 등 데이터를 입력받아 해당유저에게 도움이 될 수 있는 정책 매칭
2. LLM을 만들어 고용정책을 RAG하여 고용노동부 전용 LLM을 제작, 사용자가 하나하나 찾아보지 않아도 채팅봇에게 검색하면 LLM이 자료를 검색해 사용자에게 도움이 될 수 있는 정책들을 소개해줌.
3. 개인화된 알림 서비스:
   - 사용자가 관심 있는 정책에 업데이트가 있을 때 알림
   - 신청 마감일이 다가오는 정책 알림
   - 새로운 정책이 추가될 때 사용자 프로필에 맞는 정책 추천

이 순서대로 하나하나씩 구현해가려고 한다.

<br>

---



#### Backend

- 언어/프레임워크:
  - **FastAPI** (Python): 비동기 처리에 강점이 있고, LLM 및 벡터 DB와의 통합이 용이합니다.
- 데이터베이스:
  - **MySQL**: 관계형 데이터베이스로 사용자 정보, 정책 데이터, 알림 설정 등 구조화된 데이터 저장
- 벡터 DB:
  - **Pinecone**: 클라우드 기반 벡터 DB로, 관리가 쉽고 확장성이 좋음
- LLM 및 임베딩:
  - **OpenAI API** (GPT-3.5/4): 안정적인 성능, 한국어 지원 우수
  - **embedding 모델**: OpenAI의 text-embedding-3-small 또는 SBERT 기반 한국어 임베딩 모델

#### Frontend

- 프레임워크:
  - **React**: 컴포넌트 기반 UI 개발, 풍부한 생태계
- 디자인 시스템:
  - **Tailwind CSS**: 빠른 UI 개발

#### 인프라/배포

- 클라우드 서비스:
  - **AWS**: 확장성과 안정성
  - **Vercel**: 프론트엔드 배포
  - **Docker + Kubernetes**: 컨테이너화 및 오케스트레이션
- CI/CD:
  - **GitHub Actions**: 자동 배포 파이프라인

<br>

---



# 단계별 구현 방안

#### 1. 데이터 수집 및 처리 파이프라인

```
PDF 문서 -> OCR/텍스트 추출 -> 전처리 -> 청크 분할 -> 임베딩 생성 -> 벡터 DB 저장
```

- PDF에서 텍스트 추출: PyPDF2, pdfplumber
- 전처리: NLTK, spaCy 또는 한국어 특화 KoNLPy
- 청크 분할: LangChain
- 임베딩: OpenAI Embeddings API



#### 2. 사용자 프로필 기반 정책 매칭 시스템

사용자 입력 -> 프로필 생성 -> 벡터 검색 -> 랭킹 알고리즘 -> 정책 추천

- 프로필 관리: JWT 인증, MySQL 저장

- 벡터 검색: Pinecone

- 랭킹 알고리즘: 코사인 유사도 + 가중치 기반 커스텀 랭킹

  

#### 3. RAG 기반 LLM 챗봇

```
사용자 질문 -> 임베딩 변환 -> 관련 문서 검색 -> 컨텍스트 구성 -> LLM 추론 -> 응답 생성
```

- 프롬프트 엔지니어링: 정확한 정책 정보 제공을 위한 최적화
- RAG 구현: LangChain
- LLM 통합: OpenAI API



#### 4. 알림 시스템

```
정책 업데이트 감지 -> 사용자 프로필 매칭 -> 알림 생성 -> 푸시 알림/이메일 발송
```

- 스케줄러: Celery + Redis
- 알림 채널: WebSockets(웹), 이메일

<br>

---

### 초기 구현 로드맵

1. 1단계 (기반 구축)

   \- 1-2주

   - 백엔드 아키텍처 설정
   - 데이터베이스 스키마 설계
   - PDF 파싱 및 데이터 추출 파이프라인 구축

2. 2단계 (핵심 기능)

   \- 2-3주

   - 벡터 DB 구축 및 임베딩 생성
   - 사용자 프로필 관리 시스템
   - 기본 검색 및 매칭 알고리즘 구현

3. 3단계 (LLM 통합)

   \- 2주

   - RAG 시스템 구축
   - LLM 프롬프트 최적화
   - 챗봇 인터페이스 개발

4. 4단계 (알림 시스템)

   \- 1-2주

   - 알림 시스템 설계 및 구현
   - 정책 업데이트 모니터링 로직
   - 푸시 알림 및 이메일 통합

5. 5단계 (테스트 및 최적화)

   \- 1-2주

   - 사용자 테스트
   - 성능 최적화
   - 피드백 기반 개선



## 초기 파일구조

```
labor-policy-assistant/
├── backend/
│   ├── app/
│   │   ├── api/
│   │   │   ├── endpoints/
│   │   │   │   ├── auth.py
│   │   │   │   ├── policies.py
│   │   │   │   ├── profiles.py
│   │   │   │   └── chat.py
│   │   │   └── deps.py
│   │   ├── core/
│   │   │   ├── config.py
│   │   │   └── security.py
│   │   ├── db/
│   │   │   ├── base.py
│   │   │   └── models.py
│   │   ├── services/
│   │   │   ├── pdf_processor.py
│   │   │   ├── vector_search.py
│   │   │   ├── policy_matcher.py
│   │   │   ├── llm_service.py
│   │   │   └── notification.py
│   │   └── main.py
│   ├── celery_worker.py
│   ├── Dockerfile
│   └── requirements.txt
├── frontend/
│   ├── public/
│   ├── src/
│   │   ├── components/
│   │   ├── pages/
│   │   ├── services/
│   │   ├── App.js
│   │   └── index.js
│   ├── package.json
│   └── Dockerfile
├── data/
│   └── policies/
├── scripts/
│   ├── pdf_parser.py
│   └── vector_indexer.py
├── docker-compose.yml
└── README.md
```





####  



