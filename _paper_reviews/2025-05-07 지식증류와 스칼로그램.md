---
layout: post
title: "지식증류와 스칼로그램"
date: 2025-05-07
typora-root-url: ../
image_style: "max-width:80%; display:block; margin:1em auto; border-radius:10px; box-shadow:0px 4px 8px rgba(0,0,0,0.8);"
---



여러가지 방면으로 논문을 보던 와중

강화학습, 경량화, AI agent 등등 관한 논문을 흝어봄.

그러다 흥미로운 논문을 봤음

https://arxiv.org/abs/2501.01983

**ECG-guided individual identification via PPG**

## 지식 증류(Knowledge Distillation)의 진화

지식 증류는 원래 2015년 Hinton 등이 제안한 개념으로, 큰 모델(교사)의 "지식"을 작은 모델(학생)에게 전달하여 작은 모델의 성능을 향상시키는 기법입니다. 주요 목적은 다음과 같았습니다:

1. **모델 경량화**: 계산 자원이 제한된 환경(모바일 기기 등)에서도 고성능 모델의 지식을 활용
2. **추론 속도 향상**: 파라미터 수를 줄여 실시간 예측이 필요한 환경에서의 성능 개선
3. **메모리 효율성**: 저장 공간 및 런타임 메모리 요구사항 감소

그러나 최근 몇 년간 지식 증류의 개념이 크게 확장되어 다양한 분야에 적용되고 있습니다:

### 교차 모달 지식 증류(Cross-Modal Knowledge Distillation)

Wei 등의 ECG-PPG 연구는 지식 증류의 새로운 응용 방식인 '교차 모달 지식 증류'의 좋은 예입니다. 이는 서로 다른 데이터 모달리티 간에 지식을 전달하는 방식으로, 경량화가 아닌 '정보의 보완'에 초점을 맞춥니다.

교차 모달 지식 증류의 다른 예시들:

- 이미지에서 텍스트로의 지식 전달 (시각 정보 → 언어 표현)
- 음성에서 텍스트로의 지식 전달 (음성 특성 → 텍스트 표현)
- 비디오에서 이미지로의 지식 전달 (시공간 특성 → 공간 특성)

## **ECG-guided individual identification via PPG**

## 연구 배경 및 목적

생체인식 기술의 발전에 따라 내재적 심혈관 특성을 활용한 개인 식별 방법이 주목받고 있습니다. 특히 광혈류측정(Photoplethysmography, PPG) 신호는 접근성과 편의성 측면에서 큰 장점을 가지고 있으나, 단일 센서에서 획득되는 정보의 제한적 특성으로 인해 대규모 사용자 환경에서의 식별 정확도가 떨어진다는 한계가 있습니다. 본 연구에서는 심전도(Electrocardiogram, ECG) 신호를 '교사 모달리티'로 활용하여 PPG 신호 기반 개인 식별의 성능을 향상시키는 교차 모달 지식 증류(Cross-Modal Knowledge Distillation, CMKD) 프레임워크를 제안하고 그 효과성을 검증하고자 합니다.

### 지식 증류 기법의 적용

지식 증류는 큰 모델(교사)의 지식을 작은 모델(학생)에 전달하는 기술로, 원래는 모델 경량화를 위해 제안되었습니다. 본 연구에서는 이 개념을 확장하여 정보량이 풍부한 모달리티(ECG)에서 정보량이 적은 모달리티(PPG)로 지식을 전달하는 교차 모달 지식 증류 방식을 적용합니다. 이는 훈련 단계에서만 ECG 데이터를 필요로 하고, 실제 사용 시에는 PPG 데이터만으로 향상된 성능을 얻을 수 있다는 장점이 있습니다.

## 제안 방법론

### 교차 모달 지식 증류 프레임워크

본 연구에서 제안하는 프레임워크는 다음과 같은 주요 구성 요소를 포함합니다:

1. CLIP 기반 지식 정렬 모듈 (CLIP-based Knowledge Alignment)

   :

   - ECG와 PPG 특징 벡터 간의 도메인 격차를 줄이기 위한 투영 계층 구현
   - CLIP(Contrastive Language-Image Pre-training) 방식을 통해 두 모달리티의 임베딩을 공통 잠재 공간으로 정렬
   - 관계 기반 지식 전달을 위한 MMD(Maximum Mean Discrepancy)와 Triplet Loss 활용

2. 교차 지식 평가 모듈 (Cross-Knowledge Assessment)

   :

   - 교사 모델(ECG)과 학생 모델(PPG) 간의 교육 및 학습 결과를 양방향으로 평가
   - 교사 분류기와 학생 분류기의 교차 활용을 통한 지식 전달 효율성 평가

## 실험 설계

### 데이터셋 및 전처리

MIMIC 데이터셋에서 고품질 ECG 및 PPG 신호를 가진 341명의 데이터를 선별하여 실험에 활용합니다. 모든 신호는 125Hz로 샘플링되며, 300포인트 슬라이딩 윈도우를 사용하여 비중첩 샘플로 분할합니다. 신호의 노이즈를 제거하기 위해 표준화 기법을 적용합니다.

### 모델 아키텍처

실험의 일관성과 비교를 위해 교사 모델과 학생 모델 모두 동일한 아키텍처를 사용합니다. 구체적으로 1D ResNet34, MobileNetV1, ShuffleNetV1의 세 가지 네트워크 아키텍처를 평가하여 제안 방법의 일반화 능력을 검증합니다.

### 비교 방법

1. 기준 모델 (Baseline)

   :

   - PPG 신호만을 사용하여 표준 교차 엔트로피 손실로 훈련한 모델
   - 지식 증류나 교차 모달 학습 없이 단일 모달리티로만 훈련된 모델

2. 제안 방법

   :

   - ECG 교사 모델의 지식을 PPG 학생 모델로 전달하는 CMKD 프레임워크 적용
   - CLIP 기반 지식 정렬 모듈과 교차 지식 평가 모듈 통합

3. 최신 지식 증류 방법들

   :

   - KD [Hinton et al., 2015], RKD [Park et al., 2019], DKD [Zhao et al., 2022] 등 주요 지식 증류 방법들과 성능 비교

## 연구 초점의 진화

기존 연구에서는 ECG에서 PPG로의 신호 변환에 중점을 두었다면, 새로운 연구 방향은 지식 전달의 관점에서 두 신호 간의 관계를 재해석합니다. 구체적으로:

1. 초기 연구

   : ECG → PPG 신호 매핑 (신호 변환)

   - 목표: ECG 신호로부터 PPG 파형을 직접 예측
   - 한계: 개인별 고유 특성을 보존하기 어려움, 임상적 활용도 제한적

2. 현재 연구

   : ECG → PPG 기반 개인 식별 (지식 증류)

   - 목표: ECG의 식별력을 PPG 모델에 전달하여 개인 식별 성능 향상
   - 장점: 실용적 응용(웨어러블 인증 등), 더 높은 성능, 학술적 혁신성

------

근데 여기서 이제 생각난 게 결국 위에거를 하려면 기본적인 default 파이프라인이 있어야 한다는 거임.

default 한걸 지식 증류로 develop한거니까.

그래서 저번 데이터베이스인 WF-PPG 데이터셋 논문을 더 탐구해봄.

## **WF-PPG 데이터셋 탐색과 "PPG 파형 형태 유형 분류"라는 구체적인 목표 설정**

이 데이터셋은 손목 PPG 센서의 **접촉 압력**이라는 현실적인 변수가 PPG 신호의 파형 형태(morphology)에 미치는 영향을 심도 있게 분석할 수 있도록 설계되었습니다. 특히 WF-PPG 데이터셋은 각 손목 PPG 신호 조각에 대해 5가지 파형 형태 유형(Type 1, 2E, 2L, 1L, 3)으로 분류된 레이블(wrist_t)을 제공합니다. 이 레이블은 접촉 압력의 변화에 따라 PPG 신호가 어떻게 왜곡되거나 이상적인 형태를 보이는지를 나타냅니다.

**WF-PPG: A Wrist-finger Dual-Channel Dataset for Studying the Impact of Contact Pressure on PPG Morphology**

https://www.nature.com/articles/s41597-025-04453-7

1. **Type 1**: 단일 피크, 모세혈관 맥박과 유사, 낮은 접촉 압력에서 주로 나타남.
2. **Type 2E**: 두 개의 피크가 거의 동일한 높이, 약간 불충분한 접촉 압력. (Type 1과 Type 2L의 중첩으로 간주)
3. **Type 2L**: **이상적인 PPG 파형**. 왼쪽 피크가 오른쪽보다 뚜렷하게 크고, 이완기 절흔(dicrotic notch)이 보임. 견고하고 최적의 접촉 압력에서 나타남.
4. **Type 1L**: 이완기 피크가 사라지고 수축기 피크만 뚜렷하게 남음. 과도한 접촉 압력으로 혈관이 압박될 때 나타남.
5. **Type 3**: 위 유형에 속하지 않는, 일반적으로 잡음이 많거나 약간의 움직임으로 손상된 파형. 극도로 높거나 낮은 접촉 압력에서 신호 대 잡음비(SNR)가 나빠질 때 나타남.

그래서 이 데이터셋을 활용하여, 우선 PPG 파형의 형태 유형을 정확하게 분류해보려고 함.

그 다음 잘 되면 위의 지식증류를 해보던 말던 할거 같음

## **베이스라인 실험: 스케일로그램를 이용한 PPG 파형 형태 분류**

또, 논문을 읽다가 참고한 기존 연구를 하나 보게 댐.

"**A Novel PPG-Based Biometric Authentication System Using a Hybrid CVT-ConvMixer Architecture with Dense and Self-Attention Layers**" (https://www.mdpi.com/1424-8220/24/1/15)

PPG 신호를 스칼로그램 기법을 사용해 2D 이미지로 변환하고, 컨볼루션 비전 트랜스포머(CVT)와 컨볼루션 믹서(ConvMixer)의 특징을 결합하는 접근법

스케일로그램과 ConvMixer 계열의 아이디어를 PPG 분석에 적용한 사례

스케일로그램(Scalogram)은 웨이블릿 변환을 이용해 시계열 신호(예: 음성, 생체신호 등)의 시간-주파수 특성을 2차원 이미지로 시각화한 것입니다.

최근 PPG 신호 분석 분야에서 효과적인 접근법으로 주목받고 있는 스케일로그램(Scalogram) 기법을 활용하기로 했습니다. 스케일로그램은 1D 시계열 신호인 PPG를 시간-주파수 영역의 2D 이미지로 변환하여, 이미지 처리에 강점을 가진 딥러닝 모델이 신호의 미세한 패턴 변화를 더 효과적으로 학습할 수 있도록 돕습니다.

논문에서 베이스라인 모델 아키텍처로는 컨볼루션 믹서(ConvMixer)를 선택했습니다. ConvMixer는 비교적 가벼우면서도 이미지 분류에서 준수한 성능을 보이는 모델입니다.

다행히 해당 연구에 깃허브가 있어서 깃허브 [https://github.com/Qaisar256/Biometric-PPG] 코드를 참고하여 베이스라인을 구성

https://www.mdpi.com/1424-8220/24/1/15#B32-sensors-24-00015

https://github.com/Qaisar256/Biometric-PPG

코드가 있는 깃허브

깃허브에 BIDMC-PPG, MIMIC-PPG, Real-World-PPG를 각각 다운받아서 실험할 수 있게끔 되어있어서

얘네를 해보고 잘 되면 WF-PPG로 넘어가려 했는데, 셋 다 데이터로드가 잘 안되고 데이터셋을 코드에 어케 적용하는 방법이 안 적혀져 있어서 계속 에러나고 잘 안되어서 WF-PPG 실험으로 넘어감.

이러한 접근 방식을 바탕으로 다음과 같은 파이프라인을 구축하여 실험을 진행했습니다:

1. **데이터 로드 및 전처리 (load_preprocessed_data.py)**: WF-PPG 데이터셋에서 손목 PPG 신호와 wrist_t 레이블을 로드하고, 모델 학습에 적합한 형태로 가공합니다.
2. **스케일로그램 변환 ([PPGScalogram.py](http://ppgscalogram.py/))**: 가공된 PPG 신호 세그먼트들을 스케일로그램 이미지로 변환합니다.
3. **모델 학습 및 평가 ([ScaloGramConv.py](http://scalogramconv.py/))**: 변환된 스케일로그램 이미지들을 ConvMixer 모델에 입력하여 wrist_t (파형 형태 유형)를 분류하도록 학습시키고, 그 성능을 평가합니다.

실험 결과, 훈련 데이터에 대해서는 높은 정확도를 보였으나 검증 데이터에서는 과적합의 경향과 특정 클래스 분류의 어려움이 관찰.

코드가 잘 실험이 된건지도 잘 모르겠음. 베이스라인 코드를 좀 더 뜯어봐야댈듯.

## **더 나은 스케일로그램 기반 접근법 탐색해보니 굳이 이 데이터베이스 ,이 주제가 아니더라도 스케일로그램 기반으로 다른 데에도 접근이 가능할것같음**

## 스케일로그램 기반 PPG접근 논문들

### **Blood Pressure Estimation from Wavelet Scalogram of PPG Signals Using Convolutional Neural Networ**

- **핵심 내용**: 이 연구에서는 연속 웨이블릿 변환(CWT)을 통해 PPG 신호를 스케일로그램으로 변환하고, 이를 CNN 및 CNN-SVR 모델에 입력하여 혈압을 추정하는 방법을 제안합니다. CNN-SVR 모델은 수축기 혈압(SBP)과 이완기 혈압(DBP)에 대해 각각 6.7 mmHg, 8.9 mmHg의 RMSE를 달성하였으며, 이는 기존 모델보다 52% 향상된 성능입니다. [The Open Biomedical Engineering Journa](https://openbiomedicalengineeringjournal.com/VOLUME/18/ELOCATOR/e18741207322107/FULLTEXT/?utm_source=chatgpt.com)

### 2. **Photoplethysmography and Deep Learning: Enhancing Hypertension Risk Stratificati**

- **핵심 내용**: 이 연구는 PPG 신호를 CWT를 이용해 스케일로그램으로 변환하고, 이를 GoogLeNet과 같은 사전 학습된 CNN 모델에 입력하여 고혈압 위험을 분류합니다. 세 가지 분류 실험(NT vs. PHT, NT vs. HT, NT+PHT vs. HT)에서 각각 80.52%, 92.55%, 82.95%의 F1 점수를 기록하였습니다. [PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC6316358/?utm_source=chatgpt.com)

### 3. **PPG Signal-Based Classification of Blood Pressure Stages Using Wavelet Transformation and Pre-Trained Deep Learning Mode**

- **핵심 내용**: 이 연구는 PPG 신호를 CWT를 통해 스케일로그램으로 변환하고, 이를 InceptionV3, VGG-16, ResNet101과 같은 사전 학습된 딥러닝 모델에 입력하여 혈압 단계를 분류합니다. InceptionV3 모델은 99.5%의 정확도를 달성하였습니다. [CinC](https://cinc.org/archives/2023/pdf/CinC2023-360.pdf?utm_source=chatgpt.com)

### 4. **Integrating Transfer Learning with Scalogram Analysis for Blood Pressure Estimation from PPG Signa**

- **핵심 내용**: 이 연구에서는 PPG 신호를 CWT를 통해 스케일로그램으로 변환한 후, VGG16, ResNet50, InceptionV3 등 다양한 사전 학습된 딥러닝 모델에 입력하여 혈압을 추정합니다. ConvNeXtTiny 모델은 수축기 혈압에 대해 2.95 mmHg의 MAE를 기록하였습니다. [ResearchGate](https://www.researchgate.net/publication/381426896_Integrating_Transfer_Learning_with_Scalogram_Analysis_for_Blood_Pressure_Estimation_from_PPG_Signals?utm_source=chatgpt.com)

### 5. **Improving the Accuracy in Classification of Blood Pressure from Photoplethysmography Using Continuous Wavelet Transform and Deep Learning**

- **핵심 내용**: 이 연구는 PPG 신호를 다양한 웨이블릿(Cgau1 등)을 사용하여 스케일로그램으로 변환하고, 이를 CNN 모델에 입력하여 혈압을 분류합니다. 웨이블릿 유형과 세그먼트 길이가 정확도에 영향을 미치는 주요 요인으로 분석되었습니다.

**[ScaloGramConv.py](http://scalogramconv.py/) 코드 분석**

- **목표**: PPGScalogram.py에서 생성된 스케일로그램 데이터(scalogram_train_data.npy, scalogram_test_data.npy)를 로드하여 ConvMixer 모델을 학습시키고, 그 성능을 평가한 후 결과를 시각화합니다.

- 주요 기능

  :

  1. ScalogramDataset(Dataset) 클래스

     : PyTorch의 Dataset 클래스를 상속받아 스케일로그램 데이터를 처리합니다.

     - init

       :

       - 스케일로그램 데이터와 레이블을 받습니다.
       - _standardize_scalograms: 모든 스케일로그램 이미지의 너비(시간 축)를 target_width로 통일합니다. 너비가 크면 중앙을 기준으로 자르고, 작으면 0으로 패딩합니다.
       - 레이블이 문자열이면 정수 형태로 인코딩하고, 클래스 개수를 저장합니다.

     - **len**: 데이터셋의 총 샘플 수를 반환합니다.

     - **getitem**: 특정 인덱스(idx)의 스케일로그램과 레이블을 PyTorch 텐서 형태로 반환합니다. 스케일로그램은 [채널, 시간] 형태가 됩니다 (여기서 채널은 스케일의 수).

  2. ConvMixer(nn.Module) 클래스

     : 1D 컨볼루션 기반의 분류 모델입니다.

     - init

       :

       - proj: 입력 프로젝션 레이어. nn.Conv1d를 사용하여 입력 스케일로그램의 채널 수를 hidden_dim으로 바꾸고, 패치 단위로 다운샘플링합니다. GELU 활성화 함수와 BatchNorm1d를 사용합니다.
       - layers: 여러 개의 ConvMixer 블록을 nn.ModuleList로 구성합니다. 각 블록은 다음과 같습니다:
         - 깊이별 컨볼루션 (nn.Conv1d의 groups=hidden_dim): 각 채널(여기서는 hidden_dim의 각 차원)을 독립적으로 처리합니다.
         - GELU, BatchNorm1d
         - 포인트별 컨볼루션 (nn.Conv1d의 kernel_size=1): 채널 간 정보를 믹싱합니다.
         - GELU, BatchNorm1d
       - classifier: 분류 헤드. AdaptiveAvgPool1d로 각 채널의 평균값을 구하고, Flatten 후 nn.Linear레이어를 통해 최종 클래스 예측을 수행합니다.

     - forward:

       - 입력 x (형태: [배치, 채널(스케일), 시간])를 proj 레이어에 통과시킵니다.
       - 각 ConvMixer 블록을 순차적으로 통과시키며, 각 블록의 입력에 출력을 더하는 **잔차 연결(residual connection)**을 사용합니다.
       - classifier를 통해 최종 출력을 반환합니다.

  3. train_model 함수

     : 모델 학습을 수행합니다.

     - 학습 및 검증 손실/정확도 기록용 리스트를 초기화합니다.
     - 모델을 지정된 장치(CPU/GPU)로 옮깁니다.
     - 각 에포크마다:
       - **훈련 단계**: model.train() 모드로 설정하고, 훈련 데이터로더에서 배치를 가져와 순전파, 손실 계산, 역전파, 옵티마이저 업데이트를 수행합니다. 훈련 손실과 정확도를 기록합니다.
       - **검증 단계**: model.eval() 모드로 설정하고, 검증 데이터로더에서 배치를 가져와 순전파, 손실 계산을 수행합니다 (그래디언트 계산 안 함). 검증 손실과 정확도를 기록합니다.
       - 에포크별 결과를 출력합니다.

  4. evaluate_model 함수

     : 학습된 모델을 테스트 데이터로 평가합니다.

     - model.eval() 모드로 설정하고, 테스트 데이터로더에서 예측을 수행합니다.
     - sklearn.metrics.confusion_matrix와 sklearn.metrics.classification_report를 사용하여 혼동 행렬과 분류 보고서를 생성합니다.

  5. visualize_results 함수

     : 학습 결과(손실, 정확도 곡선)와 평가 결과(혼동 행렬)를 시각화합니다.

     - matplotlib.pyplot과 seaborn.heatmap을 사용합니다.
     - 생성된 그래프를 파일로 저장합니다 (scalogram_model_training.png, scalogram_confusion_matrix.png).

  6. main 함수

     : 전체 파이프라인을 실행합니다.

     - **데이터 로드**: scalogram_train_data.npy와 scalogram_test_data.npy를 로드합니다.
     - **스케일로그램 크기 표준화**: 로드된 스케일로그램들의 너비(시간 축)가 다양하므로, 너비의 중앙값을 target_width로 설정하여 ScalogramDataset에서 이를 기준으로 표준화합니다.
     - **하이퍼파라미터 설정**: 배치 크기, 에포크 수, 학습률, 사용 장치 등을 설정합니다.
     - **데이터셋 및 데이터 로더 생성**: ScalogramDataset 객체를 만들고, 훈련 데이터셋을 다시 훈련용과 검증용으로 80:20 비율로 분할합니다. DataLoader를 생성합니다.
     - **모델 초기화**: ConvMixer 모델을 설정된 파라미터로 생성합니다. 입력 채널 수는 스케일로그램의 스케일 수(높이)가 됩니다.
     - **손실 함수 및 옵티마이저 정의**: nn.CrossEntropyLoss와 optim.Adam을 사용합니다.
     - **모델 학습**: train_model 함수를 호출합니다.
     - **모델 평가**: evaluate_model 함수를 호출합니다.
     - **결과 시각화**: visualize_results 함수를 호출합니다. 레이블 이름을 가져와 혼동 행렬에 표시합니다.
     - **모델 저장**: 학습된 모델의 가중치를 scalogram_convmixer_model.pt 파일로 저장합니다.

**제공된 학습 결과 이미지 및 로그 분석**

- 실행 로그

  :

  - 데이터 로딩: 훈련 데이터 160개, 테스트 데이터 41개의 스케일로그램 이미지가 로드되었습니다.
  - 스케일로그램 형태: 초기 스케일로그램들의 너비(시간 축 길이)가 다양함을 보여줍니다 (예: 69, 72, 71, 64, 61).
  - 목표 너비: 너비의 중앙값인 68로 설정되어, 모든 스케일로그램이 이 너비로 표준화됩니다.
  - 레이블 인코딩: 문자열 레이블 ('1', '1L', '2E', '2L', '3')이 정수 (0~4)로 인코딩되었습니다. (로그에 두 번 나오는데, 하나는 훈련 데이터셋, 다른 하나는 테스트 데이터셋에 대한 것일 수 있습니다. 테스트셋에서는 '2L' 레이블이 없는 것으로 보입니다.)
  - 입력 데이터 형태: [32, 100, 68] (배치 크기, 스케일 수, 표준화된 시간 너비).
  - 학습 과정: 50 에포크 동안 훈련 손실/정확도와 검증 손실/정확도가 출력됩니다.
    - 훈련 정확도는 에포크가 진행됨에 따라 거의 1.0에 가깝게 상승하고, 훈련 손실은 0에 가깝게 감소합니다. 이는 모델이 훈련 데이터에는 잘 적응하고 있음을 보여줍니다.
    - 검증 정확도는 초반에 상승하다가 약 0.6~0.7 사이에서 정체되거나 변동하는 모습을 보입니다. 검증 손실은 특정 지점 이후로는 감소하지 않거나 오히려 증가하는 경향을 보일 수 있습니다 (그래프에서 확인 필요). 이는 **과적합(overfitting)**의 가능성을 시사합니다. 모델이 훈련 데이터에 너무 특화되어 새로운 데이터(검증 데이터)에 대한 일반화 성능이 떨어지는 현상입니다.
  - 모델 평가 결과 (Classification Report):
    - **Accuracy: 0.61**. 전체 테스트 샘플 중 61%를 올바르게 분류했습니다.
    - 레이블별 성능:
      - 레이블 0 ('1')과 2 ('2E')는 비교적 괜찮은 precision (정밀도)과 recall (재현율)을 보입니다.
      - 레이블 1 ('1L')과 3 (`'2L' 또는 '3', 혼동 행렬과 비교 필요)은 precision과 recall이 낮습니다. 특히 레이블 3은 recall이 0.25로 매우 낮습니다.
      - 레이블 4 ('3', 만약 테스트셋에 있다면)는 아예 예측되지 않았거나 실제 샘플이 없어 (support=0) 평가 지표가 0.0으로 나옵니다. (sklearn 경고 메시지는 이 부분을 지적합니다: "Recall is ill-defined and being set to 0.0 in labels with no true samples.")
    - Macro avg F1-score: 0.42. 클래스 불균형을 고려하지 않은 평균 F1 점수.
    - Weighted avg F1-score: 0.64. 클래스별 샘플 수를 고려한 가중 평균 F1 점수.

- 학습 및 검증 손실/정확도 그래프 (첫 번째 이미지)

  :

  - 손실 그래프 (왼쪽)

    :

    - 파란색 (훈련 손실): 에포크가 진행됨에 따라 꾸준히 감소합니다.
    - 주황색 (검증 손실): 초반에는 감소하다가 특정 에포크(약 15~20 에포크) 이후로는 감소세가 둔화되거나 오히려 증가하며 변동성이 커지는 모습을 보입니다. 이는 명확한 과적합의 징후입니다.

  - 정확도 그래프 (오른쪽)

    :

    - 파란색 (훈련 정확도): 에포크가 진행됨에 따라 1.0에 가깝게 상승합니다.
    - 주황색 (검증 정확도): 초반에는 상승하지만, 훈련 정확도만큼 높게 올라가지 못하고 약 0.6~0.7 수준에서 정체되며 변동합니다. 훈련 정확도와의 격차가 점점 벌어지는 것 또한 과적합을 나타냅니다.

- 혼동 행렬 (두 번째 이미지)

  :

  - Y축: 실제 레이블, X축: 예측 레이블.

  - 레이블 이름: '1', '1L', '2E', '2L', '3' (로그의 인코딩 순서와 일치).

  - 대각선 요소

    : 올바르게 분류된 샘플 수.

    - 레이블 '1': 12개 정답.
    - 레이블 '2E': 11개 정답.

  - 비대각선 요소

    : 오분류된 샘플 수.

    - 실제 '1'인데 '1L'로 2개, '2E'로 3개 오분류.
    - 실제 '1L'인데 '1'로 2개, '2E'로 1개 오분류. (정답은 1개)
    - 실제 '2E'인데 '1'로 3개, '3'으로 2개 오분류.
    - 실제 '2L'인데 '2E'로 1개, '3'으로 3개 오분류. (정답 없음)
    - 실제 '3'인데 아무것도 정답으로 예측되지 않음 (모두 오분류).

  - 레이블 '3' (실제)은 어떠한 예측도 받지 못했고, 레이블 '2L' (실제)은 예측에서 1건만 '2L'로 맞혔습니다. 이는 Classification Report에서 해당 클래스들의 낮은 recall과 F1-score로 나타납니다.

  - 특히, 레이블 '2L' (인덱스 3)의 실제 샘플은 4개였는데, classification report에서 recall이 0.25였으므로 1개만 맞춘 것이고, 혼동 행렬에서는 실제 2L 축에서 예측 2L에 1이 찍혀있습니다.

  - 레이블 '3' (인덱스 4)의 실제 샘플은 classification report에서 support가 0이었으므로, 테스트 데이터에 이 레이블이 없었던 것으로 보입니다. 따라서 혼동 행렬의 마지막 행(실제 레이블 '3')은 모두 0이 되어야 합니다 (이미지상으로는 그렇게 보입니다).

**종합적인 평가 및 개선 방향**

- 모델은 훈련 데이터에 대해서는 매우 잘 학습했지만 (높은 훈련 정확도, 낮은 훈련 손실), 검증 및 테스트 데이터에 대해서는 일반화 성능이 상대적으로 낮습니다. 즉, **과적합(overfitting)**이 발생했습니다.

- 일부 클래스(특히 '1L', '2L', '3')에 대한 분류 성능이 매우 낮습니다. 이는 데이터 불균형 문제이거나 해당 클래스의 특징이 다른 클래스와 매우 유사하여 구분이 어려운 경우일 수 있습니다.

- 개선 방향

  :

  1. 과적합 완화

     :

     - **데이터 증강 (Data Augmentation)**: 스케일로그램 이미지에 대해 시간 축 이동, 노이즈 추가, 주파수 축 마스킹 등의 기법을 적용하여 훈련 데이터의 다양성을 늘립니다.
     - **규제 (Regularization)**: 모델의 가중치에 L1 또는 L2 규제를 추가하거나, Dropout 레이어를 ConvMixer 블록 내 또는 분류기 전에 추가합니다.
     - **조기 종료 (Early Stopping)**: 검증 손실이 더 이상 개선되지 않거나 증가하기 시작하면 학습을 중단합니다. 현재 코드에는 구현되어 있지 않지만, 추가할 수 있습니다.
     - **모델 복잡도 줄이기**: ConvMixer의 레이어 수(num_layers)나 은닉 차원(hidden_dim)을 줄여 모델을 더 단순하게 만듭니다.

  2. 데이터 불균형 처리

     :

     - load_preprocessed_data.py 단계에서 레이블별 샘플 수를 확인하고, 적은 수의 클래스에 대해 오버샘플링(SMOTE 등) 또는 많은 수의 클래스에 대해 언더샘플링을 고려합니다.
     - 손실 함수에서 클래스 가중치(class weights)를 사용합니다 (예: nn.CrossEntropyLoss(weight=class_weights)).

  3. **하이퍼파라미터 튜닝**: 학습률, 배치 크기, 옵티마이저 종류 등을 변경하며 최적의 조합을 찾습니다.

  4. **모델 아키텍처 변경**: ConvMixer 외에 다른 CNN 아키텍처(예: ResNet-유사 구조, EfficientNet 등) 또는 스케일로그램에 적합한 다른 모델을 시도해볼 수 있습니다.

  5. **특징 공학**: 스케일로그램 생성 시 사용되는 웨이블릿 종류, 스케일 범위 등을 조정하여 더 유용한 특징을 추출하도록 시도합니다.

이 코드는 스케일로그램을 이용한 PPG 신호 분류의 전체 과정을 잘 보여주는 예시이며, 제공된 결과는 실제 딥러닝 프로젝트에서 흔히 마주치는 과적합 및 클래스 불균형 문제를 잘 보여주고 있습니다. 위에서 제시된 개선 방향들을 적용하면 모델 성능을 향상시킬 수 있을 것입니다.
