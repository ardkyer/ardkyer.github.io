---
layout: post
title: "하이퍼파라미터"
date: 2024-09-16
typora-root-url: ../

---

## 하이퍼파라미터

하이퍼파라미터는 모델 학습 과정이 시작되기 전에 설정되는 구성 변수

![image-20240916215333968](/assets/img/image-20240916215333968.png)

## 하이퍼파라미터 최적화가 필요한 이유

1. 모델 성능 향상: 적절한 하이퍼파라미터 선택은 모델의 정확도와 일반화 능력을 크게 향상시킬 수 있습니다.
2. 학습 시간 단축: 효율적인 하이퍼파라미터는 학습 시간을 단축시킬 수 있습니다.
3. 과적합/과소적합 방지: 최적화된 하이퍼파라미터는 모델이 데이터에 더 잘 일반화되도록 돕습니다.

![image-20240916215435606](/assets/img/image-20240916215435606.png)

## 하이퍼파라미터 튜닝 방법

## Grid Search

- 정의: 미리 정의된 하이퍼파라미터 값들의 모든 조합을 시도하는 방법
- 장점: 모든 조합을 시도하므로 전역 최적해를 찾을 가능성이 높음
- 단점: 계산 비용이 매우 높고, 차원이 증가할수록 비효율적

## Random Search

- 정의: 정의된 범위 내에서 무작위로 하이퍼파라미터 조합을 선택하여 시도
- 장점: Grid Search보다 효율적이며, 중요한 하이퍼파라미터를 더 잘 탐색할 수 있음
- 단점: 완전한 무작위성으로 인해 최적 조합을 놓칠 수 있음

## Bayesian Search

- 정의: 이전 시도 결과를 바탕으로 다음 시도할 하이퍼파라미터 조합을 선택
- 장점: 효율적인 탐색이 가능하며, 적은 시도로도 좋은 결과를 얻을 수 있음
- 단점: 구현이 복잡하고 초기 설정에 따라 결과가 달라질 수 있음

## 하이퍼파라미터 최적화 도구

Weights & Biases (WandB) Sweep

![image-20240916215636148](/assets/img/image-20240916215636148.png)

Optuna

![image-20240916215712406](/assets/img/image-20240916215712406.png)
