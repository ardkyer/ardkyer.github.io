---
layout: post
title: "데이터의 가치측정 및 해석"
date: 2024-09-06
typora-root-url: ../

---

## 특징 중요도(Feature Attribution)와 데이터 중요도(Data Attribution)

데이터의 중요도를 측정하는 방법은 크게 두 가지로 나눌 수 있습니다:

- 특징 중요도: 모델의 예측에 각 특징(feature)이 얼마나 영향을 미치는지 측정합니다. 예를 들어, Gradient-weighted Class Activation Mapping(Grad-CAM) 같은 방법이 이에 해당합니다.
- 데이터 중요도: 각 훈련 데이터 포인트가 모델의 전반적인 성능에 얼마나 기여하는지 측정합니다. 인플루언스 함수는 이 카테고리에 속합니다.

## 데이터 중요도의 활용

데이터 중요도 측정은 다음과 같은 상황에서 유용하게 사용될 수 있습니다:

- 모델 해석: 특정 예측 결과에 가장 큰 영향을 미친 훈련 데이터를 식별할 수 있습니다.
- 데이터 품질 관리: 모델 성능에 부정적인 영향을 미치는 데이터를 찾아 제거할 수 있습니다.
- 데이터 증강: 모델 성능 향상에 도움이 되는 데이터의 특성을 파악하여 유사한 데이터를 추가로 수집할 수 있습니다.
- 개인정보 보호: 특정 데이터 포인트를 제거했을 때의 영향을 빠르게 추정할 수 있습니다.

## Influence Function

인플루언스 함수는 각 훈련 데이터 포인트가 모델의 예측에 미치는 영향을 효율적으로 추정하는 방법입니다. 이 방법의 핵심 아이디어는 다음과 같습니다:

- 특정 데이터 포인트를 미세하게 변화시켰을 때 모델 파라미터가 얼마나 변하는지 계산합니다.
- 이를 통해 해당 데이터 포인트가 모델의 전반적인 성능에 미치는 영향을 추정합니다.

## 인플루언스 함수의 수학적 기반

인플루언스 함수의 수학적 기반은 다음과 같습니다:

- 모델의 손실 함수를 L(z, θ)라고 할 때 (z는 데이터 포인트, θ는 모델 파라미터), 최적의 파라미터 θ*에서 특정 데이터 포인트 z의 영향력은 다음과 같이 근사될 수 있습니다:

$$
I(z, z_test) ≈ -∇θ L(z_test, θ*)^T H^(-1) ∇θ L(z, θ*)
$$

여기서 H는 헤시안 행렬(손실 함수의 2차 미분)입니다.

이 수식은 복잡해 보이지만, 직관적으로는 "테스트 데이터 포인트의 그래디언트와 훈련 데이터 포인트의 그래디언트의 유사도"를 나타낸다고 볼 수 있습니다.

## 인플루언스 함수의 장단점

장점:

- 모델을 여러 번 재학습할 필요 없이 각 데이터 포인트의 영향을 빠르게 추정할 수 있습니다.
- 모델의 결정 과정을 이해하는 데 도움이 됩니다.
- 데이터 품질 관리에 유용하게 활용될 수 있습니다.

단점:

- 헤시안 행렬의 역행렬 계산이 필요해 대규모 모델에서는 계산 비용이 높을 수 있습니다.
- 비선형성이 강한 모델에서는 근사의 정확도가 떨어질 수 있습니다.

## 인플루언스 함수의 확장

최근 연구에서는 인플루언스 함수를 더욱 발전시켜, 데이터의 변형(perturbation)까지 고려할 수 있는 방법이 제안되었습니다. 이를 통해 데이터 증강이나 적대적 공격(adversarial attack) 같은 상황에서도 데이터의 영향을 분석할 수 있게 되었습니다.

## Data Shapley

Data Shapley는 게임 이론에서 유래한 Shapley value 개념을 데이터 가치 측정에 적용한 방법입니다.

동기:

- 기존의 Leave-one-out (LOO) 방식은 공정한 가치 평가 조건을 만족하지 못합니다.
- 우리는 데이터 포인트가 모델 성능에 기여하는 정도를 정확하게 측정하고 싶습니다.

이 방법은 세 가지 중요한 조건을 만족합니다:

1. 모델 성능에 영향을 주지 않는 데이터의 가치는 0이 됩니다.
2. 동일한 영향을 주는 데이터는 같은 가치를 갖습니다.
3. 성능 지표가 개별 점수의 합으로 표현될 경우, 전체 가치는 각 성능 지표에 대한 가치의 합이 됩니다.

하지만 이 방법은 계산 복잡도가 매우 높아 실제 적용이 어렵습니다. 이를 해결하기 위해 Monte Carlo 근사법 등을 사용합니다.

응용:

- 잘못 라벨링된 데이터 탐지
- 노이즈가 있는 데이터 식별

## 강화학습 기반 방법 (DVRL)

Data Valuation using Reinforcement Learning (DVRL)은 강화학습을 활용해 데이터의 가치를 측정하는 방법입니다.

동기:

- 기존 방법들은 대규모 데이터셋과 복잡한 모델에 적용하기 어렵습니다.
- 학습 과정에서 실시간으로 데이터의 가치를 평가하고 싶습니다.

방법론: DVRL은 다음과 같은 목적 함수를 최적화합니다:

![image-20240905000501640](/assets/img/image-20240905000501640.png)

활용 방안:

- 적은 양의 데이터로도 전체 데이터를 사용한 것과 비슷한 성능을 낼 수 있습니다.
- 일부 데이터를 제거했을 때 오히려 성능이 향상되는 경우를 찾아낼 수 있습니다.

## Data-OOB

Data-OOB는 Out-of-Bag 추정을 이용한 데이터 가치 측정 방법입니다.

동기:

- DVRL은 별도의 검증 데이터셋이 필요하다는 단점이 있습니다.
- 검증 데이터 없이도 scalable하고 통계적 해석이 가능한 방법이 필요합니다.

방법론: Data-OOB는 배깅(Bagging) 기법을 기반으로 합니다.

특징:

- 별도의 검증 데이터셋이 필요 없습니다.
- LOO나 영향력 함수에 비해 계산 효율성이 높습니다.
- 통계적 해석이 가능합니다 (infinitesimal jackknife influence function과의 관계).

결론: 데이터의 가치를 측정하는 것은 모델 성능 향상, 데이터 품질 관리, 모델 해석 등 다양한 측면에서 중요합니다. Data Shapley, DVRL, Data-OOB 각각의 방법은 고유한 장단점을 가지고 있으며, 상황에 따라 적절한 방법을 선택하여 사용할 수 있습니다. 앞으로 더 효율적이고 정확한 데이터 가치 측정 방법이 개발될 것으로 기대됩니다.
