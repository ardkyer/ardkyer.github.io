---
layout: post
title: "변분추론 II"
date: 2024-09-04
typora-root-url: ../

---

## 1. MFVI (Mean-Field Variational Inference)

MFVI는 복잡한 확률 분포를 더 단순한 독립적인 분포들의 곱으로 근사하는 방법입니다.

- **비유**: 복잡한 퍼즐을 여러 개의 작은 조각으로 나누어 각각 해결하는 것과 비슷합니다.
- **장점**: 계산이 간단해지고 빨라집니다.
- **단점**: 변수 간의 상호작용을 무시할 수 있어 정확도가 떨어질 수 있습니다.

## 2. 변분 추론의 응용

### 2.1 베르누이 혼합 모델 (Mixture of Bernoulli)

- E-step: 각 데이터 포인트가 각 컴포넌트에 속할 확률을 계산합니다 (사후 분포 계산)
- M-step: 이 확률을 바탕으로 모델 파라미터 (ㅠk와 qk)를 업데이트합니다.

![image-20240904153721391](/assets/img/image-20240904153721391.png)

![image-20240904153809661](/assets/img/image-20240904153809661.png)

- **설명**: 여러 개의 동전 던지기 실험이 섞여 있는 상황을 모델링합니다.
- **응용**: 이진 데이터(예: 사용자가 아이템을 좋아하는지 여부)를 분석할 때 사용됩니다.

### 2.2 가우시안 혼합 모델 (Gaussian Mixture Model, GMM)

- **설명**: 여러 개의 정규 분포가 섞여 있는 상황을 모델링합니다.
- **응용**: 클러스터링, 이미지 분할, 음성 인식 등에 사용됩니다.

### 2.3 베이지안 가우시안 혼합 모델 (Bayesian Gaussian Mixture Model, BGMM)

![image-20240904154138769](/assets/img/image-20240904154138769.png)

- **설명**: GMM에 베이지안 접근법을 적용한 모델입니다.
- 장점
  - 초기값에 덜 민감합니다.
  - 파라미터의 불확실성을 고려합니다.
  - 문제가 될 수 있는 특이점을 피할 수 있습니다.

**BGMM에서 정확한 추론이 어려운 이유**
BGMM(베이지안 가우시안 혼합 모델)은 데이터를 여러 그룹으로 나누고 각 그룹의 특성을 파악하는 복잡한 통계 모델입니다.   이 모델에서 우리가 알고 싶은 것(예: 각 데이터 포인트가 어느 그룹에 속하는지)을 정확히 계산하려면, 수많은 가능성을 모두 고려해야 합니다.   이는 마치 수백만 개의 퍼즐 조각을 동시에 맞추려는 것과 같아서, 실제로는 불가능합니다.



## 3. EM 알고리즘과 변분 추론의 비교

### 3.1 EM (Expectation-Maximization) 알고리즘

- **목적**: 로그 주변 가능도(log marginal likelihood)를 최대화합니다.
- **과정**: 기대값 계산(E-step)과 최대화(M-step)를 반복합니다.

### 3.2 변분 추론 (VI)

- **목적**: ELBO(Evidence Lower BOund)를 최대화합니다.
- **특징**: 실제 사후 분포를 근사하려고 합니다.

### 3.3 차이점

- EM은 정확한 사후 분포를 사용하지만, VI는 근사된 사후 분포를 사용합니다.
- VI는 EM보다 더 복잡한 모델에 적용할 수 있습니다.

## 4. 변분 추론의 최근 응용: 추천 시스템

- 변분 오토인코더(VAE)나 확산 모델(Diffusion Model) 기반의 추천 시스템에서 활용됩니다.
- 사용자의 선호도를 모델링하고 새로운 아이템을 추천하는 데 사용됩니다.

## 결론

변분 추론 II는 더 복잡한 확률 모델을 다루는 방법을 제공합니다. 이를 통해 현실 세계의 복잡한 데이터를 더 잘 이해하고 분석할 수 있게 됩니다. 특히 추천 시스템과 같은 실제 응용 분야에서 중요한 역할을 하고 있습니다.
