---
layout: post
title: "베이스라인 공부"
date: 2024-11-15
typora-root-url: ../
image_style: "max-width:80%; display:block; margin:1em auto; border-radius:10px; box-shadow:0px 4px 8px rgba(0,0,0,0.8);"

---

## 베이스라인이나 공부해보자. 

순서는 아래로 하나하나씩 한줄씩 공부해보자.

preprocessing.py 부터 보는 것이 좋겠습니다.

데이터가 어떻게 전처리되는지 이해하는 것이 첫 단계입니다
메타데이터(감독, 장르, 작가 등)가 어떻게 처리되는지 볼 수 있습니다


datasets.py

전처리된 데이터가 어떤 형태로 모델에 입력되는지 이해할 수 있습니다
데이터 로딩 및 배치 생성 과정을 볼 수 있습니다


modules.py & models.py

모델의 기본 구성 요소와 전체 아키텍처를 이해할 수 있습니다


trainers.py & run_train.py

실제 학습이 어떻게 이루어지는지 볼 수 있습니다


inference.py

학습된 모델이 어떻게 추천을 생성하는지 이해할 수 있습니다

utils.py 

보조함수

---



**preprocessing.py**

```
import pandas as pd  

def main():
    genres_df = pd.read_csv("../data/train/genres.tsv", sep="\t")
    
    # genres_df의 "genre" 컬럼을 수치형으로 변환합니다
    # pd.factorize는 문자열 카테고리를 0부터 시작하는 정수로 인코딩합니다
    # 예: 'Action' -> 0, 'Drama' -> 1, 'Comedy' -> 2 등
    # array는 변환된 숫자값들의 배열, index는 원래 장르명들의 리스트입니다
    array, index = pd.factorize(genres_df["genre"])
    
    # 변환된 숫자값들을 다시 genres_df의 "genre" 컬럼에 할당합니다
    genres_df["genre"] = array
    
    # groupby를 사용하여 각 영화(item)별로 장르 리스트를 만들고
    # 이를 JSON 형태로 저장합니다
    # 예: {"1": [0,1,2], "2": [1,3]} -> 영화 1번은 0,1,2번 장르를, 영화 2번은 1,3번 장르를 가짐
    genres_df.groupby("item")["genre"].apply(list).to_json(
        "data/Ml_item2attributes.json"
    )

if __name__ == "__main__":
    main()
```

우선은 뭐 별거 없긴하다. 그냥 genres파일을 숫자값으로 인코딩해서 json형식으로 변환한건데 

인코딩해서 수치 데이터로 만들어서 딥러닝 모델에 처리가능하게 한건가? Embedding 레이어를 위하여? 근데 이게 인코딩이 순서에 따른 인코딩아닌가? 각 장르별 상관관계가 가까운 순서대로 인코딩하는게 낫지 않을까?

one-hot encoding으로 바꾸는게 낫지않을까? 근데 그러면 희소 벡터 많이 생겨서 연산량 많아질 거 같긴한데 좀 더 나으려나?

그리고 다른 director나 title같은건 인코딩 못할거같은데 어카지? 굳이 인코딩을 해야하나? 좀 자주 나오는 얘들로만 전처리해서 인코딩해버릴까?

**해볼거**

1. **genres를 원-핫인코딩으로 변경**
2. **다른 파일들 차원의 저주 안나도록 전처리해서 인코딩해보기**

---

**datasets.py**

얜 좀 코드가 길다. 다는 못 쓸거 같고 아래와 같이 두개의 class가 있는데

```
# PyTorch의 Dataset 클래스를 상속받는 사전학습용 데이터셋 클래스

class PretrainDataset(Dataset):


# SASRec 모델을 위한 데이터셋 클래스
class SASRecDataset(Dataset):
```

PretrainDataset 클래스의 주요 특징:

1. 데이터 준비
   - 시퀀스 마스킹 (일부 아이템을 마스크로 대체)
   - 세그먼트 예측을 위한 데이터 준비
   - 부정 샘플링 (학습에 사용할 부정 예제 생성)
2. 데이터 처리
   - 패딩 (모든 시퀀스를 동일한 길이로 맞춤)
   - 속성 정보 변환 (원-핫 인코딩)
   - 텐서 변환 (PyTorch 모델 입력용)
3. 검증
   - 모든 시퀀스 길이가 올바른지 확인
   - 데이터 형식이 올바른지 검증



SASRecDataset 클래스의 주요 특징:

1. 데이터 타입별(train/valid/test/submission) 다른 처리 방식 적용
2. 시계열 특성을 고려한 입력/타겟 분리
3. 부정 샘플링을 통한 학습 데이터 보강
4. 테스트 시 별도의 부정 샘플 사용 가능









